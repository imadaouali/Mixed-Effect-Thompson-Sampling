{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 364,
     "status": "ok",
     "timestamp": 1652373079763,
     "user": {
      "displayName": "Imad Aouali",
      "userId": "10957666911602104909"
     },
     "user_tz": 240
    },
    "id": "dUrLMhAcZYDY",
    "outputId": "e7637e0a-2d44-4760-e4d6-bcbb43502924",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Imports and defaults\n",
    "import itertools\n",
    "import joblib\n",
    "from joblib import Parallel, delayed\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.linalg import block_diag\n",
    "import time\n",
    "\n",
    "mpl.style.use(\"classic\")\n",
    "mpl.rcParams[\"figure.figsize\"] = [5, 3]\n",
    "\n",
    "mpl.rcParams[\"axes.linewidth\"] = 0.75\n",
    "mpl.rcParams[\"figure.facecolor\"] = \"w\"\n",
    "mpl.rcParams[\"grid.linewidth\"] = 0.75\n",
    "mpl.rcParams[\"lines.linewidth\"] = 0.75\n",
    "mpl.rcParams[\"patch.linewidth\"] = 0.75\n",
    "mpl.rcParams[\"xtick.major.size\"] = 3\n",
    "mpl.rcParams[\"ytick.major.size\"] = 3\n",
    "\n",
    "mpl.rcParams[\"pdf.fonttype\"] = 42\n",
    "mpl.rcParams[\"ps.fonttype\"] = 42\n",
    "mpl.rcParams[\"font.size\"] = 9\n",
    "mpl.rcParams[\"axes.titlesize\"] = \"medium\"\n",
    "mpl.rcParams[\"legend.fontsize\"] = \"medium\"\n",
    "\n",
    "import platform\n",
    "print(\"python %s\" % platform.python_version())\n",
    "print(\"matplotlib %s\" % mpl.__version__)\n",
    "print(\"%d joblib cores\" % joblib.cpu_count())\n",
    "\n",
    "def linestyle2dashes(style):\n",
    "  if style == \"--\":\n",
    "    return (3, 3)\n",
    "  elif style == \":\":\n",
    "    return (0.5, 2.5)\n",
    "  else:\n",
    "    return (None, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "f7uZWkUjRmUs",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Bandit environments\n",
    "class CoBandit(object):\n",
    "  \"\"\"Contextual bandit with K arms.\"\"\"\n",
    "\n",
    "  def __init__(self, K, contexts, Theta, sigma=1.0):\n",
    "    self.K = K  # number of arms\n",
    "    self.contexts = np.copy(contexts)  # [number of contexts] x d feature matrix\n",
    "    self.num_contexts = self.contexts.shape[0]  # number of contexts\n",
    "    self.d = self.contexts.shape[1]  # number of features\n",
    "    self.Theta = np.copy(Theta)  # [number of arms] x d arm parameters\n",
    "    self.sigma = sigma  # reward noise\n",
    "\n",
    "    self.randomize()\n",
    "\n",
    "  def randomize(self):\n",
    "    # randomly choose one context per arm (does not have to be the same)\n",
    "    ndx = np.random.randint(self.num_contexts, size=self.K)\n",
    "    self.X = self.contexts[ndx, :]\n",
    "\n",
    "    # mean and stochastic rewards\n",
    "    self.mut = (self.X * self.Theta).sum(axis=-1)\n",
    "    self.rt = self.mut + self.sigma * np.random.randn(self.K)\n",
    "    self.best_arm = np.argmax(self.mut)\n",
    "\n",
    "  def reward(self, arm):\n",
    "    # instantaneous reward of the arm\n",
    "    return self.rt[arm]\n",
    "\n",
    "  def regret(self, arm):\n",
    "    # instantaneous regret of the arm\n",
    "    return self.rt[self.best_arm] - self.rt[arm]\n",
    "\n",
    "  def pregret(self, arm):\n",
    "    # expected regret of the arm\n",
    "    return self.mut[self.best_arm] - self.mut[arm]\n",
    "\n",
    "  def print(self):\n",
    "    return \"Contextual bandit: %d dimensions, %d arms\" % (self.d, self.K)\n",
    "\n",
    "\n",
    "def evaluate_one(Alg, params, env, n, period_size=1):\n",
    "  \"\"\"One run of a bandit algorithm.\"\"\"\n",
    "  alg = Alg(env, n, params)\n",
    "\n",
    "  regret = np.zeros(n // period_size)\n",
    "  for t in range(n):\n",
    "    # generate state\n",
    "    env.randomize()\n",
    "\n",
    "    # take action and update agent\n",
    "    arm = alg.get_arm(t)\n",
    "    alg.update(t, arm, env.reward(arm))\n",
    "\n",
    "    # track performance\n",
    "    regret_at_t = env.regret(arm)\n",
    "    regret[t // period_size] += regret_at_t\n",
    "\n",
    "  return regret, alg\n",
    "\n",
    "\n",
    "def evaluate(Alg, params, env, n=1000, period_size=1, printout=True):\n",
    "  \"\"\"Multiple runs of a bandit algorithm.\"\"\"\n",
    "  if printout:\n",
    "    print(\"Evaluating %s\" % Alg.print(), end=\"\")\n",
    "  start = time.time()\n",
    "\n",
    "  num_exps = len(env)\n",
    "  regret = np.zeros((n // period_size, num_exps))\n",
    "  alg = num_exps * [None]\n",
    "\n",
    "  output = Parallel(n_jobs=-1)(delayed(evaluate_one)(Alg, params, env[ex], n, period_size)\n",
    "    for ex in range(num_exps))\n",
    "  for ex in range(num_exps):\n",
    "    regret[:, ex] = output[ex][0]\n",
    "    alg[ex] = output[ex][1]\n",
    "  if printout:\n",
    "    print(\" %.1f seconds\" % (time.time() - start))\n",
    "\n",
    "  if printout:\n",
    "    total_regret = regret.sum(axis=0)\n",
    "    print(\"Regret: %.2f +/- %.2f (median: %.2f, max: %.2f, min: %.2f)\" %\n",
    "      (total_regret.mean(), total_regret.std() / np.sqrt(num_exps),\n",
    "      np.median(total_regret), total_regret.max(), total_regret.min()))\n",
    "\n",
    "  return regret, alg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "Lkl993UjR6E_",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Bandit algorithms\n",
    "class LinBanditAlg:\n",
    "  def __init__(self, env, n, params):\n",
    "    self.env = env  # bandit environment that the agent interacts with\n",
    "    self.K = self.env.K  # number of arms\n",
    "    self.d = self.env.d  # number of features\n",
    "    self.n = n  # horizon\n",
    "    self.Theta0 = np.copy(env.mar_Theta0)  # prior means of arm parameters\n",
    "    self.Sigma0 = np.copy(env.mar_Sigma0)  # prior covariance of arm parameters\n",
    "    self.sigma = self.env.sigma  # reward noise\n",
    "\n",
    "    # override default values\n",
    "    for attr, val in params.items():\n",
    "      if isinstance(val, np.ndarray):\n",
    "        setattr(self, attr, np.copy(val))\n",
    "      else:\n",
    "        setattr(self, attr, val)\n",
    "\n",
    "    self.Lambda0 = np.zeros((self.K, self.d, self.d))\n",
    "    for i in range(self.K):\n",
    "      self.Lambda0[i, :, :] = np.linalg.inv(self.Sigma0[i, :, :])\n",
    "\n",
    "    # sufficient statistics\n",
    "    self.G = np.zeros((self.K, self.d, self.d))\n",
    "    self.B = np.zeros((self.K, self.d))\n",
    "\n",
    "  def update(self, t, arm, r):\n",
    "    # update sufficient statistics\n",
    "    x = self.env.X[arm, :]\n",
    "    self.G[arm, :, :] += np.outer(x, x) / np.square(self.sigma)\n",
    "    self.B[arm, :] += x * r / np.square(self.sigma)\n",
    "\n",
    "\n",
    "class LinTS(LinBanditAlg):\n",
    "  def get_arm(self, t):\n",
    "    self.mu = np.zeros(self.K)\n",
    "    for i in range(self.K):\n",
    "      # linear model posterior\n",
    "      Gt = self.Lambda0[i, :, :] + self.G[i, :, :]\n",
    "      Sigma_hat = np.linalg.inv(Gt)\n",
    "      theta_hat = np.linalg.solve(Gt, self.Lambda0[i, :, :].dot(self.Theta0[i, :]) + self.B[i, :])\n",
    "      \n",
    "      # posterior sampling\n",
    "      theta_tilde = np.random.multivariate_normal(theta_hat, Sigma_hat)\n",
    "      self.mu[i] = self.env.X[i, :].dot(theta_tilde)\n",
    "    \n",
    "    arm = np.argmax(self.mu)\n",
    "    return arm\n",
    "\n",
    "  @staticmethod\n",
    "  def print():\n",
    "    return \"LinTS\"\n",
    "\n",
    "\n",
    "class LinUCB(LinBanditAlg):\n",
    "  def __init__(self, env, n, params):\n",
    "    LinBanditAlg.__init__(self, env, n, params)\n",
    "\n",
    "    self.cew = self.confidence_ellipsoid_width(n)\n",
    "\n",
    "  def confidence_ellipsoid_width(self, t):\n",
    "    # Theorem 2 in Abassi-Yadkori (2011)\n",
    "    # Improved Algorithms for Linear Stochastic Bandits\n",
    "    delta = 1 / self.n\n",
    "    L = np.amax(np.linalg.norm(self.env.contexts, axis=1))\n",
    "    Lambda = np.trace(self.Lambda0, axis1=-2, axis2=-1).max() / self.d\n",
    "    R = self.sigma\n",
    "    S = np.sqrt(self.d)\n",
    "    width = np.sqrt(Lambda) * S + \\\n",
    "      R * np.sqrt(self.d * np.log((1 + t * np.square(L) / Lambda) / delta))\n",
    "    return width\n",
    "\n",
    "  def get_arm(self, t):\n",
    "    self.mu = np.zeros(self.K)\n",
    "    for i in range(self.K):\n",
    "      # linear model posterior\n",
    "      Gt = self.Lambda0[i, :, :] + self.G[i, :, :]\n",
    "      Sigma_hat = np.linalg.inv(Gt)\n",
    "      theta_hat = np.linalg.solve(Gt, self.Lambda0[i, :, :].dot(self.Theta0[i, :]) + self.B[i, :])\n",
    "\n",
    "      # UCBs\n",
    "      Sigma_hat /= np.square(self.sigma)\n",
    "      self.mu[i] = self.env.X[i, :].dot(theta_hat) + self.cew * \\\n",
    "        np.sqrt(self.env.X[i, :].dot(Sigma_hat).dot(self.env.X[i, :]))\n",
    "\n",
    "    arm = np.argmax(self.mu)\n",
    "    return arm\n",
    "\n",
    "  @staticmethod\n",
    "  def print():\n",
    "    return \"LinUCB\"\n",
    "\n",
    "\n",
    "class meTS:\n",
    "  def __init__(self, env, n, params):\n",
    "    self.env = env  # bandit environment that the agent interacts with\n",
    "    self.K = self.env.K  # number of arms\n",
    "    self.d = self.env.d  # number of features\n",
    "    self.n = n  # horizon\n",
    "    self.A = self.env.A\n",
    "    self.L = self.A.shape[1]\n",
    "    self.mu_psi = np.copy(self.env.mu_psi)\n",
    "    self.Sigma_psi = np.copy(self.env.Sigma_psi)\n",
    "    self.Sigma0 = np.copy(self.env.Sigma0)\n",
    "    self.sigma = self.env.sigma  # reward noise\n",
    "\n",
    "    # override default values\n",
    "    for attr, val in params.items():\n",
    "      if isinstance(val, np.ndarray):\n",
    "        setattr(self, attr, np.copy(val))\n",
    "      else:\n",
    "        setattr(self, attr, val)\n",
    "\n",
    "    self.Lambda_psi = np.linalg.inv(self.Sigma_psi)\n",
    "    self.Lambda0 = np.zeros((self.K, self.d, self.d))\n",
    "    for i in range(self.K):\n",
    "      self.Lambda0[i, :, :] = np.linalg.inv(self.Sigma0[i, :, :])\n",
    "\n",
    "    # sufficient statistics\n",
    "    self.G = np.zeros((self.K, self.d, self.d))\n",
    "    self.B = np.zeros((self.K, self.d))\n",
    "\n",
    "  def update(self, t, arm, r):\n",
    "    # update sufficient statistics\n",
    "    x = self.env.X[arm, :]\n",
    "    self.G[arm, :, :] += np.outer(x, x) / np.square(self.sigma)\n",
    "    self.B[arm, :] += x * r / np.square(self.sigma)\n",
    "\n",
    "  def get_arm(self, t):\n",
    "    small_eye = 1e-3 * np.eye(self.d)\n",
    "    \n",
    "    # effect posterior\n",
    "    Lambda_t = np.copy(self.Lambda_psi)\n",
    "    mu_t = self.Lambda_psi.dot(self.mu_psi)\n",
    "    for i in range(self.K):\n",
    "      aiai = np.outer(self.A[i, :], self.A[i, :])\n",
    "      inv_Gi = np.linalg.inv(self.G[i, :, :] + small_eye)\n",
    "      prior_adjusted_Gi = np.linalg.inv(self.Sigma0[i, :, :] + inv_Gi)\n",
    "      Lambda_t += np.kron(aiai, prior_adjusted_Gi)\n",
    "      prior_adjusted_Bi = prior_adjusted_Gi.dot(inv_Gi.dot(self.B[i, :]))\n",
    "      mu_t += np.outer(self.A[i, :], prior_adjusted_Bi).flatten()\n",
    "    \n",
    "    # posterior sampling\n",
    "    Sigma_t = np.linalg.inv(Lambda_t)\n",
    "    mu_t = Sigma_t.dot(mu_t)\n",
    "    Psi_tilde = np.random.multivariate_normal(mu_t, Sigma_t)\n",
    "    matPsi_tilde = np.reshape(Psi_tilde, (self.L, self.d))  # matrix version\n",
    "    \n",
    "    self.mu = np.zeros(self.K)\n",
    "    for i in range(self.K):\n",
    "      # arm parameter posterior\n",
    "      Sigma_ti = np.linalg.inv(self.Lambda0[i, :, :] + self.G[i, :, :])\n",
    "      mu_ti = self.Lambda0[i, :, :].dot(self.A[i, :].dot(matPsi_tilde)) + self.B[i, :]\n",
    "      mu_ti = Sigma_ti.dot(mu_ti)\n",
    "      \n",
    "      # posterior sampling\n",
    "      theta_tilde = np.random.multivariate_normal(mu_ti, Sigma_ti)\n",
    "      self.mu[i] = self.env.X[i, :].dot(theta_tilde)\n",
    "    \n",
    "    arm = np.argmax(self.mu)\n",
    "    return arm\n",
    "\n",
    "  @staticmethod\n",
    "  def print():\n",
    "    return \"meTS\"\n",
    "\n",
    "\n",
    "class meTSFactored:\n",
    "  def __init__(self, env, n, params):\n",
    "    self.env = env  # bandit environment that the agent interacts with\n",
    "    self.K = self.env.K  # number of arms\n",
    "    self.d = self.env.d  # number of features\n",
    "    self.n = n  # horizon\n",
    "    self.A = self.env.A\n",
    "    self.L = self.A.shape[1]\n",
    "    self.mu_psi = np.copy(self.env.mu_psi)\n",
    "    self.Sigma_psi = np.copy(self.env.Sigma_psi)\n",
    "    self.Sigma0 = np.copy(self.env.Sigma0)\n",
    "    self.sigma = self.env.sigma  # reward noise\n",
    "\n",
    "    # override default values\n",
    "    for attr, val in params.items():\n",
    "      if isinstance(val, np.ndarray):\n",
    "        setattr(self, attr, np.copy(val))\n",
    "      else:\n",
    "        setattr(self, attr, val)\n",
    "\n",
    "    self.Lambda_psi = np.linalg.inv(self.Sigma_psi)\n",
    "    self.Lambda0 = np.zeros((self.K, self.d, self.d))\n",
    "    for i in range(self.K):\n",
    "      self.Lambda0[i, :, :] = np.linalg.inv(self.Sigma0[i, :, :])\n",
    "\n",
    "    # sufficient statistics\n",
    "    self.G = np.zeros((self.K, self.d, self.d))\n",
    "    self.B = np.zeros((self.K, self.d))\n",
    "\n",
    "  def update(self, t, arm, r):\n",
    "    # update sufficient statistics\n",
    "    x = self.env.X[arm, :]\n",
    "    self.G[arm, :, :] += np.outer(x, x) / np.square(self.sigma)\n",
    "    self.B[arm, :] += x * r / np.square(self.sigma)\n",
    "\n",
    "  def get_arm(self, t):\n",
    "    small_eye = 1e-3 * np.eye(self.d)\n",
    "    \n",
    "    # effect posterior\n",
    "    Lambda_t = []\n",
    "    mu_t = []\n",
    "    for l in range(self.L):\n",
    "      Lambda_psi_l = self.Lambda_psi[l*self.d:(l+1)*self.d,l*self.d:(l+1)*self.d]\n",
    "      Lambda_t.append(np.copy(Lambda_psi_l))\n",
    "      mu_t.append(Lambda_psi_l.dot(self.mu_psi[l*self.d:(l+1)*self.d]))\n",
    "\n",
    "    for i in range(self.K):\n",
    "      inv_Gi = np.linalg.inv(self.G[i, :, :] + small_eye)\n",
    "      prior_adjusted_Gi = np.linalg.inv(self.Sigma0[i, :, :] + inv_Gi)\n",
    "      prior_adjusted_Bi = prior_adjusted_Gi.dot(inv_Gi.dot(self.B[i, :]))\n",
    "      \n",
    "      for l in range(self.L):\n",
    "        Lambda_t[l] += (self.A[i, l]**2) * prior_adjusted_Gi\n",
    "        mu_t[l] += self.A[i, l] * prior_adjusted_Bi\n",
    "\n",
    "    # posterior sampling\n",
    "    Sigma_t = []\n",
    "    for l in range(self.L):\n",
    "      Sigma_t.append(np.linalg.inv(Lambda_t[l]))\n",
    "      mu_t[l] = Sigma_t[l].dot(mu_t[l])\n",
    "\n",
    "    Sigma_t = block_diag(*Sigma_t)\n",
    "    mu_t = np.concatenate(mu_t)\n",
    "    \n",
    "    Psi_tilde = np.random.multivariate_normal(mu_t, Sigma_t)\n",
    "    matPsi_tilde = np.reshape(Psi_tilde, (self.L, self.d))  # matrix version\n",
    "    \n",
    "    self.mu = np.zeros(self.K)\n",
    "    for i in range(self.K):\n",
    "      # arm parameter posterior\n",
    "      Sigma_ti = np.linalg.inv(self.Lambda0[i, :, :] + self.G[i, :, :])\n",
    "      mu_ti = self.Lambda0[i, :, :].dot(self.A[i, :].dot(matPsi_tilde)) + self.B[i, :]\n",
    "      mu_ti = Sigma_ti.dot(mu_ti)\n",
    "      \n",
    "      # posterior sampling\n",
    "      theta_tilde = np.random.multivariate_normal(mu_ti, Sigma_ti)\n",
    "      self.mu[i] = self.env.X[i, :].dot(theta_tilde)\n",
    "    \n",
    "    arm = np.argmax(self.mu)\n",
    "    return arm\n",
    "\n",
    "  @staticmethod\n",
    "  def print():\n",
    "    return \"meTSFactored\"\n",
    "\n",
    "\n",
    "class HierTS:\n",
    "  def __init__(self, env, n, params):\n",
    "    self.env = env  # bandit environment that the agent interacts with\n",
    "    self.K = self.env.K  # number of arms\n",
    "    self.d = self.env.d  # number of features\n",
    "    self.n = n  # horizon\n",
    "    self.A = self.env.A\n",
    "    self.L = self.A.shape[1]\n",
    "    self.mu_psi = np.mean(self.env.mu_psi.reshape(self.L, self.d), axis=0) # average of effect parameters\n",
    "    self.Sigma_psi = (1/(self.L**2)) * np.sum([self.env.Sigma_psi[l*self.d:(l+1)*self.d,l*self.d:(l+1)*self.d] for l in range(self.L)], axis=0) # corresponding cov matrix\n",
    "    self.Sigma0 = np.copy(self.env.Sigma0)\n",
    "    self.sigma = self.env.sigma  # reward noise\n",
    "\n",
    "    # override default values\n",
    "    for attr, val in params.items():\n",
    "      if isinstance(val, np.ndarray):\n",
    "        setattr(self, attr, np.copy(val))\n",
    "      else:\n",
    "        setattr(self, attr, val)\n",
    "\n",
    "    self.Lambda_psi = np.linalg.inv(self.Sigma_psi)\n",
    "    self.Lambda0 = np.zeros((self.K, self.d, self.d))\n",
    "    for i in range(self.K):\n",
    "      self.Lambda0[i, :, :] = np.linalg.inv(self.Sigma0[i, :, :])\n",
    "\n",
    "    # sufficient statistics\n",
    "    self.G = np.zeros((self.K, self.d, self.d))\n",
    "    self.B = np.zeros((self.K, self.d))\n",
    "\n",
    "  def update(self, t, arm, r):\n",
    "    # update sufficient statistics\n",
    "    x = self.env.X[arm, :]\n",
    "    self.G[arm, :, :] += np.outer(x, x) / np.square(self.sigma)\n",
    "    self.B[arm, :] += x * r / np.square(self.sigma)\n",
    "\n",
    "  def get_arm(self, t):\n",
    "    small_eye = 1e-3 * np.eye(self.d)\n",
    "    \n",
    "    # effect parameter posterior\n",
    "    Lambda_t = np.copy(self.Lambda_psi)\n",
    "    mu_t = self.Lambda_psi.dot(self.mu_psi)\n",
    "    for i in range(self.K):\n",
    "      inv_Gi = np.linalg.inv(self.G[i, :, :] + small_eye)\n",
    "      prior_adjusted_Gi = np.linalg.inv(self.Sigma0[i, :, :] + inv_Gi)\n",
    "      Lambda_t += prior_adjusted_Gi\n",
    "      prior_adjusted_Bi = prior_adjusted_Gi.dot(inv_Gi.dot(self.B[i, :]))\n",
    "      mu_t += prior_adjusted_Bi\n",
    "    \n",
    "    # posterior sampling\n",
    "    Sigma_t = np.linalg.inv(Lambda_t)\n",
    "    mu_t = Sigma_t.dot(mu_t)\n",
    "    Psi_tilde = np.random.multivariate_normal(mu_t, Sigma_t)\n",
    "    \n",
    "    self.mu = np.zeros(self.K)\n",
    "    for i in range(self.K):\n",
    "      # arm parameter posterior\n",
    "      Sigma_ti = np.linalg.inv(self.Lambda0[i, :, :] + self.G[i, :, :])\n",
    "      mu_ti = self.Lambda0[i, :, :].dot(Psi_tilde) + self.B[i, :]\n",
    "      mu_ti = Sigma_ti.dot(mu_ti)\n",
    "      \n",
    "      # posterior sampling\n",
    "      theta_tilde = np.random.multivariate_normal(mu_ti, Sigma_ti)\n",
    "      self.mu[i] = self.env.X[i, :].dot(theta_tilde)\n",
    "    \n",
    "    arm = np.argmax(self.mu)\n",
    "    return arm\n",
    "\n",
    "  @staticmethod\n",
    "  def print():\n",
    "    return \"HierTS\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma = 1\n",
    "n = 5000\n",
    "num_runs = 50\n",
    "\n",
    "algs = [\n",
    "  (\"meTS\", {}, \"red\", \"-\", \"meTS-Lin\"),\n",
    "  (\"meTSFactored\", {}, \"orange\", \"-\", \"meTS-Lin-Fa\"),\n",
    "  (\"HierTS\", {}, \"gray\", \"-\", \"HierTS\"),\n",
    "  (\"LinUCB\", {}, \"cyan\", \"-\", \"LinUCB\"),\n",
    "  (\"LinTS\", {}, \"blue\", \"-\", \"LinTS\")\n",
    "]\n",
    "\n",
    "\n",
    "#exps = [\n",
    "#  {\"K\": 100, \"L\": 3, \"d\": 2},\n",
    "#  {\"K\": 100, \"L\": 3, \"d\": 5},\n",
    "#  {\"K\": 100, \"L\": 3, \"d\": 10},\n",
    "#  {\"K\": 50, \"L\": 3, \"d\": 2},\n",
    "#  {\"K\": 50, \"L\": 3, \"d\": 5},\n",
    "#  {\"K\": 50, \"L\": 3, \"d\": 10},\n",
    "#  {\"K\": 20, \"L\": 3, \"d\": 2},\n",
    "#  {\"K\": 20, \"L\": 3, \"d\": 5},\n",
    "#  {\"K\": 20, \"L\": 3, \"d\": 10}\n",
    "#]\n",
    "\n",
    "exps = [\n",
    "  {\"K\": 100, \"L\": 3, \"d\": 2}\n",
    "]\n",
    "\n",
    "for exp in exps:\n",
    "  # set parameters of the experiment\n",
    "  for attr, val in exp.items():\n",
    "    globals()[attr] = val\n",
    "\n",
    "  # bandit environments\n",
    "  envs = []\n",
    "  for run in range(num_runs):\n",
    "    # possible contexts\n",
    "    contexts = 2 * np.random.rand(100, d) - 1\n",
    "\n",
    "    # mixing coefficients\n",
    "    A = 2 * np.random.rand(K, L) - 1\n",
    "    \n",
    "    #matA: matrix formulation of the mixing weights for action parameters  \n",
    "    matA = np.zeros((K*d, L*d))\n",
    "    for i in range(K):\n",
    "        matA[i*d:(i+1)*d, :] = np.kron(A[i, :].T, np.eye(d))\n",
    "\n",
    "    # effect and action priors\n",
    "    mu_psi = np.zeros(d * L)\n",
    "    mat_mu_Psi = np.reshape(mu_psi, (L, d))\n",
    "    Sigma_psi = 3*np.eye(d * L)\n",
    "    Sigma0 = np.tile(np.eye(d), (K, 1, 1))\n",
    "    \n",
    "    # marginal uncertainty of arm parameters\n",
    "    mar_Theta0 = np.zeros((K, d))\n",
    "    mar_Sigma0 = np.copy(Sigma0)        \n",
    "    for i in range(K):\n",
    "        matAi = matA[i*d:(i+1)*d, :]\n",
    "        mar_Theta0[i, :] = matAi.dot(mu_psi)\n",
    "        mar_Sigma0[i, :, :] = Sigma0[i, :, :] + matAi.dot(Sigma_psi).dot(matAi.T)\n",
    "\n",
    "    # generate effect parameters\n",
    "    Psi = np.random.multivariate_normal(mu_psi, Sigma_psi)\n",
    "    matPsi = np.reshape(Psi, (L, d))  # matrix version\n",
    "\n",
    "    # generate arm parameters\n",
    "    Theta = np.random.randn(K, d)\n",
    "    for i in range(K):\n",
    "      Theta[i, :] = np.random.multivariate_normal(A[i, :].dot(matPsi), Sigma0[i, :, :])\n",
    "\n",
    "    # initialize bandit environment\n",
    "    env = CoBandit(K, contexts, Theta, sigma=sigma)\n",
    "\n",
    "    # pass parameters for algorithm initialization (not used in simulation)\n",
    "    env.A = A\n",
    "    env.mu_psi = mu_psi\n",
    "    env.Sigma_psi = Sigma_psi\n",
    "    env.Sigma0 = Sigma0\n",
    "    env.mar_Theta0 = mar_Theta0\n",
    "    env.mar_Sigma0 = mar_Sigma0\n",
    "\n",
    "    envs.append(env)\n",
    "\n",
    "  # simulation\n",
    "  for alg in algs:\n",
    "    # all runs for a single algorithm\n",
    "    alg_class = globals()[alg[0]]\n",
    "    regret, logs = evaluate(alg_class, alg[1], envs, n)\n",
    "\n",
    "    # # save results\n",
    "    #fname = \"Results/Synthetic/Linear/%s_K=%d_L=%d_d=%d\" % (alg[4], K, L, d)\n",
    "    #np.save(fname + \".npy\", regret)\n",
    "\n",
    "    # plot\n",
    "    cum_regret = regret.cumsum(axis=0)\n",
    "    step = np.arange(1, n + 1)\n",
    "    sube = (step.size // 10) * np.arange(1, 11) - 1\n",
    "    plt.plot(step, cum_regret.mean(axis=1),\n",
    "      alg[2], dashes=linestyle2dashes(alg[3]), label=alg[4])\n",
    "    plt.errorbar(step[sube], cum_regret[sube, :].mean(axis=1),\n",
    "      cum_regret[sube, :].std(axis=1) / np.sqrt(cum_regret.shape[1]),\n",
    "      fmt=\"none\", ecolor=alg[2])\n",
    "\n",
    "  plt.title(\"Linear Bandit, K = %d, L = %d, d = %d\" % (K, L, d))\n",
    "  plt.xlabel(\"Round n\")\n",
    "  plt.ylabel(\"Regret\")\n",
    "  plt.ylim(bottom=0)\n",
    "  plt.legend(loc=\"upper left\", frameon=False)\n",
    "\n",
    "  plt.tight_layout()\n",
    "  plt.show()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "GenHierTS.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python Criteo (MOAB #49947)",
   "language": "python",
   "name": "python-kernel-49947"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
