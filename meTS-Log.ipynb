{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "dUrLMhAcZYDY",
    "outputId": "31bb0c27-489c-4d61-85e8-6002f5252ed5",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Imports and defaults\n",
    "import copy\n",
    "import itertools\n",
    "from joblib import Parallel, delayed\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.linalg import block_diag\n",
    "\n",
    "import time\n",
    "\n",
    "\n",
    "mpl.rcParams[\"figure.figsize\"] = [6, 4]\n",
    "\n",
    "mpl.rcParams[\"axes.linewidth\"] = 0.75\n",
    "mpl.rcParams[\"errorbar.capsize\"] = 3\n",
    "mpl.rcParams[\"figure.facecolor\"] = \"w\"\n",
    "mpl.rcParams[\"grid.linewidth\"] = 0.75\n",
    "mpl.rcParams[\"lines.linewidth\"] = 0.75\n",
    "mpl.rcParams[\"patch.linewidth\"] = 0.75\n",
    "mpl.rcParams[\"xtick.major.size\"] = 3\n",
    "mpl.rcParams[\"ytick.major.size\"] = 3\n",
    "\n",
    "mpl.rcParams[\"pdf.fonttype\"] = 42\n",
    "mpl.rcParams[\"ps.fonttype\"] = 42\n",
    "mpl.rcParams[\"font.size\"] = 10\n",
    "mpl.rcParams[\"axes.titlesize\"] = \"medium\"\n",
    "\n",
    "import platform\n",
    "print(\"python %s\" % platform.python_version())\n",
    "print(\"matplotlib %s\" % mpl.__version__)\n",
    "\n",
    "def linestyle2dashes(style):\n",
    "  if style == \"--\":\n",
    "    return (3, 3)\n",
    "  elif style == \":\":\n",
    "    return (0.5, 2.5)\n",
    "  else:\n",
    "    return (None, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f7uZWkUjRmUs",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Bandit environments and simulator\n",
    "#@title Logistic bandit environment\n",
    "class LogBandit(object):\n",
    "  \"\"\"Logistic bandit.\"\"\"\n",
    "\n",
    "  def __init__(self, K, contexts, Theta, sigma):    \n",
    "    self.K = K  # number of arms\n",
    "    self.contexts = np.copy(contexts)  # [number of contexts] x d feature matrix\n",
    "    self.num_contexts = self.contexts.shape[0]  # number of contexts\n",
    "    self.d = self.contexts.shape[1]  # number of features\n",
    "    self.Theta = np.copy(Theta)  # [number of arms] x d arm parameters\n",
    "    self.sigma = sigma #reward noise\n",
    "    self.randomize()\n",
    "\n",
    "  def sigmoid(self, x):\n",
    "    y = 1 / (1 + np.exp(- x))\n",
    "    return y\n",
    "\n",
    "  def randomize(self):\n",
    "    # randomly choose one context per arm (does not have to be the same)\n",
    "    self.ndx = np.random.randint(self.num_contexts, size=self.K)\n",
    "    self.X = self.contexts[self.ndx, :]\n",
    "\n",
    "    # mean and stochastic rewards\n",
    "    self.mut = self.sigmoid((self.X * self.Theta).sum(axis=-1))\n",
    "    self.rt = (np.random.rand(self.K) < self.mut).astype(float)\n",
    "    self.best_arm = np.argmax(self.mut)\n",
    "\n",
    "  def reward(self, arm):\n",
    "    # instantaneous reward of the arm\n",
    "    return self.rt[arm]\n",
    "\n",
    "  def regret(self, arm):\n",
    "    # instantaneous regret of the arm\n",
    "    return self.rt[self.best_arm] - self.rt[arm]\n",
    "\n",
    "  def pregret(self, arm):\n",
    "    # expected regret of the arm\n",
    "    return self.mu[self.best_arm] - self.mu[arm]\n",
    "\n",
    "  def print(self):\n",
    "    return \"Logistic bandit: %d dimensions, %d arms\" % (self.d, self.K)\n",
    "\n",
    "\n",
    "def evaluate_one(Alg, params, env, n, period_size=1):\n",
    "  \"\"\"One run of a bandit algorithm.\"\"\"\n",
    "  alg = Alg(env, n, params)\n",
    "\n",
    "  regret = np.zeros(n // period_size)\n",
    "  for t in range(n):\n",
    "    # generate state\n",
    "    env.randomize()\n",
    "\n",
    "    # take action and update agent\n",
    "    arm = alg.get_arm(t)\n",
    "    alg.update(t, arm, env.reward(arm))\n",
    "\n",
    "    # track performance\n",
    "    regret_at_t = env.regret(arm)\n",
    "    regret[t // period_size] += regret_at_t\n",
    "\n",
    "  return regret, alg\n",
    "\n",
    "def evaluate(Alg, params, env, n=1000, period_size=1, printout=True):\n",
    "  \"\"\"Multiple runs of a bandit algorithm.\"\"\"\n",
    "  if printout:\n",
    "    print(\"Evaluating %s\" % Alg.print(), end=\"\")\n",
    "  start = time.time()\n",
    "\n",
    "  num_exps = len(env)\n",
    "  regret = np.zeros((n // period_size, num_exps))\n",
    "  alg = num_exps * [None]\n",
    "\n",
    "  output = Parallel(n_jobs=-1)(delayed(evaluate_one)(Alg, params, env[ex], n, period_size)\n",
    "    for ex in range(num_exps))\n",
    "  for ex in range(num_exps):\n",
    "    regret[:, ex] = output[ex][0]\n",
    "    alg[ex] = output[ex][1]\n",
    "  if printout:\n",
    "    print(\" %.1f seconds\" % (time.time() - start))\n",
    "\n",
    "  if printout:\n",
    "    total_regret = regret.sum(axis=0)\n",
    "    print(\"Regret: %.2f +/- %.2f (median: %.2f, max: %.2f, min: %.2f)\" %\n",
    "      (total_regret.mean(), total_regret.std() / np.sqrt(num_exps),\n",
    "      np.median(total_regret), total_regret.max(), total_regret.min()))\n",
    "\n",
    "  return regret, alg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "Lkl993UjR6E_",
    "tags": []
   },
   "outputs": [],
   "source": [
    "class LogBanditAlg:\n",
    "  def __init__(self, env, n, params):\n",
    "    self.env = env  # bandit environment that the agent interacts with\n",
    "    self.K = self.env.K  # number of arms\n",
    "    self.d = self.env.d  # number of features\n",
    "    self.n = n  # horizon\n",
    "    self.Theta0 = np.copy(env.mar_Theta0)  # prior means of arm parameters\n",
    "    self.Sigma0 = np.copy(env.mar_Sigma0)  # prior covariance of arm parameters\n",
    "    self.sigma = self.env.sigma  # reward noise\n",
    "\n",
    "    self.irls_Theta = np.copy(env.mar_Theta0)\n",
    "    self.irls_error = 1e-3\n",
    "    self.irls_num_iter = 1000\n",
    "    self.batch_size = 30 #self.n\n",
    "    \n",
    "    for attr, val in params.items():\n",
    "      setattr(self, attr, val)\n",
    "\n",
    "    # sufficient statistics\n",
    "    self.pulls = np.zeros(self.K, dtype=int) # number of observations for each arm\n",
    "    \n",
    "    self.Lambda0 = np.zeros((self.K, self.d, self.d))\n",
    "    for i in range(self.K):\n",
    "      self.Lambda0[i, :, :] = np.linalg.inv(self.Sigma0[i, :, :])\n",
    "\n",
    "    self.G = np.zeros((self.K, self.d, self.d))\n",
    "    \n",
    "    self.context_ndx = [[] for i in range(self.K)]\n",
    "    self.r = [[] for i in range(self.K)]\n",
    "\n",
    "  def update(self, t, arm, r):    \n",
    "    self.r[arm].append(r)\n",
    "    self.pulls[arm] += 1\n",
    "    self.context_ndx[arm].append(self.env.ndx[arm])\n",
    "    \n",
    "    x = self.env.X[arm, :]\n",
    "    self.G[arm, :, :] += np.outer(x, x) / np.square(self.sigma)      \n",
    "    \n",
    "    \n",
    "  def sigmoid(self, x):\n",
    "    y = 1 / (1 + np.exp(- x))\n",
    "    return y\n",
    "\n",
    "  def solve(self, arm):\n",
    "    # iterative reweighted least squares for Bayesian logistic regression\n",
    "    # Sections 4.3.3 and 4.5.1 in Bishop (2006)\n",
    "    # Pattern Recognition and Machine Learning\n",
    "    \n",
    "    small_eye = 1e-5 * np.eye(self.d)\n",
    "    theta = np.copy(self.irls_Theta[arm,:])\n",
    "    nbr_obs = self.pulls[arm]\n",
    "    t = self.r[arm]\n",
    "    context_ndx = self.context_ndx[arm]\n",
    "\n",
    "    num_iter = 0\n",
    "    \n",
    "    while num_iter < self.irls_num_iter:\n",
    "        theta_old = np.copy(theta)\n",
    "        Gram = small_eye\n",
    "        Phiyt = np.zeros(self.d)\n",
    "\n",
    "        if nbr_obs <= self.batch_size:\n",
    "            batch = np.arange(nbr_obs)\n",
    "        else:\n",
    "            batch = np.random.choice(nbr_obs, size=self.batch_size)\n",
    "\n",
    "        for i in batch:\n",
    "            x = self.env.contexts[context_ndx[i],:]\n",
    "            y = self.sigmoid((x * theta).sum())\n",
    "            Gram += y * (1-y) * np.outer(x, x) \n",
    "            Phiyt += (y-t[i]) * x\n",
    "\n",
    "        PhiRz = Gram.dot(theta) - Phiyt\n",
    "        theta = np.linalg.solve(Gram, PhiRz)\n",
    "        \n",
    "        if np.linalg.norm(theta - theta_old) < self.irls_error:\n",
    "            break;\n",
    "        num_iter += 1\n",
    "    \n",
    "    if num_iter == self.irls_num_iter:\n",
    "        self.irls_Theta[arm,:] = self.Theta0[arm,:]\n",
    "    else:\n",
    "        self.irls_Theta[arm,:] = np.copy(theta)\n",
    "\n",
    "    return theta, Gram\n",
    "\n",
    "class LogUCB(LogBanditAlg):\n",
    "  def __init__(self, env, n, params):\n",
    "    LogBanditAlg.__init__(self, env, n, params)\n",
    "\n",
    "    self.cew = self.confidence_ellipsoid_width(n)\n",
    "    self.inv_Gt = np.zeros((self.K, self.d, self.d))\n",
    "    \n",
    "  def confidence_ellipsoid_width(self, t):\n",
    "    # Section 4.1 in Filippi (2010)\n",
    "    # Parametric Bandits: The Generalized Linear Case\n",
    "    delta = 1 / self.n\n",
    "    c_m = np.amax(np.linalg.norm(self.env.contexts, axis=1))\n",
    "    c_mu = 0.25 # minimum derivative of the mean function\n",
    "    k_mu = 0.25\n",
    "    kappa = np.sqrt(3 + 2 * np.log(1 + 2 * np.square(c_m / self.sigma)))\n",
    "    R_max = 1.0\n",
    "    width = (2 * k_mu * kappa * R_max / c_mu) * \\\n",
    "      np.sqrt(2 * self.d * np.log(t) * np.log(2 * self.d * self.n / delta))\n",
    "    return width\n",
    "\n",
    "  def get_arm(self, t):\n",
    "    self.mu = np.zeros(self.K)\n",
    "    \n",
    "    if t==0:\n",
    "        for i in range(self.K):\n",
    "            Gt = self.Lambda0[i, :, :] + self.G[i, :, :]\n",
    "            self.inv_Gt[i, :, :] = np.linalg.inv(Gt)\n",
    "            theta, _ = self.solve(i)\n",
    "    else:\n",
    "        Gt = self.Lambda0[self.At, :, :] + self.G[self.At, :, :]\n",
    "        self.inv_Gt[self.At, :, :] = np.linalg.inv(Gt)\n",
    "        theta, _ = self.solve(self.At)\n",
    "                \n",
    "    for i in range(self.K):\n",
    "        # UCBs\n",
    "        theta_hat = self.irls_Theta[i,:]\n",
    "        inv_Gt = self.inv_Gt[i, :, :]\n",
    "        self.mu[i] = self.sigmoid(self.env.X[i, :].dot(theta_hat)) + self.cew * \\\n",
    "          np.sqrt((self.env.X[i, :].dot(inv_Gt).dot(self.env.X[i, :])))\n",
    "\n",
    "    arm = np.argmax(self.mu)\n",
    "    self.At = arm\n",
    "    \n",
    "    return arm\n",
    "\n",
    "  @staticmethod\n",
    "  def print():\n",
    "    return \"GLM-UCB\"\n",
    "\n",
    "\n",
    "class UCBLog(LogBanditAlg):\n",
    "  def __init__(self, env, n, params):\n",
    "    LogBanditAlg.__init__(self, env, n, params)\n",
    "\n",
    "    self.cew = self.confidence_ellipsoid_width(n)\n",
    "    self.inv_Gt = np.zeros((self.K, self.d, self.d))\n",
    "    \n",
    "  def confidence_ellipsoid_width(self, t):\n",
    "    # Theorem 2 in Li (2017)\n",
    "    # Provably Optimal Algorithms for Generalized Linear Contextual Bandits\n",
    "    delta = 1 / self.n\n",
    "    sigma = 0.5\n",
    "    kappa = 0.25 # minimum derivative of a constrained mean function\n",
    "    width = (sigma / kappa) * \\\n",
    "      np.sqrt((self.d / 2) * np.log(1 + 2 * self.n / self.d) + \\\n",
    "      np.log(1 / delta))\n",
    "    return width\n",
    "\n",
    "  def get_arm(self, t):\n",
    "    self.mu = np.zeros(self.K)\n",
    "    \n",
    "    if t==0:\n",
    "        for i in range(self.K):\n",
    "            Gt = self.Lambda0[i, :, :] + self.G[i, :, :]\n",
    "            self.inv_Gt[i, :, :] = np.linalg.inv(Gt)\n",
    "            theta, _ = self.solve(i)\n",
    "    else:\n",
    "        Gt = self.Lambda0[self.At, :, :] + self.G[self.At, :, :]\n",
    "        self.inv_Gt[self.At, :, :] = np.linalg.inv(Gt)\n",
    "        theta, _ = self.solve(self.At)\n",
    "                \n",
    "    for i in range(self.K):\n",
    "        # UCBs\n",
    "        theta_hat = self.irls_Theta[i,:]\n",
    "        inv_Gt = self.inv_Gt[i, :, :]\n",
    "        self.mu[i] = self.sigmoid(self.env.X[i, :].dot(theta_hat)) + self.cew * \\\n",
    "          np.sqrt((self.env.X[i, :].dot(inv_Gt).dot(self.env.X[i, :])))\n",
    "\n",
    "    arm = np.argmax(self.mu)\n",
    "    self.At = arm\n",
    "    \n",
    "    return arm\n",
    "\n",
    "  @staticmethod\n",
    "  def print():\n",
    "    return \"UCB-GLM\"\n",
    "\n",
    "\n",
    "\n",
    "class LogTS(LogBanditAlg):\n",
    "  def __init__(self, env, n, params):\n",
    "    LogBanditAlg.__init__(self, env, n, params)\n",
    "    self.Grams = np.zeros((self.K, self.d, self.d))\n",
    "\n",
    "  def get_arm(self, t):\n",
    "    self.mu = np.zeros(self.K)\n",
    "    \n",
    "    if t==0:\n",
    "        for i in range(self.K):\n",
    "            thetabar, Gram = self.solve(i)\n",
    "            #Gram_inv = np.linalg.inv(self.Lambda0[self.At, :, :] + Gram)\n",
    "            #self.inv_Grams[i,:,:] = Gram_inv\n",
    "            self.Grams[i,:,:] = Gram\n",
    "    else:\n",
    "        thetabar, Gram = self.solve(self.At)\n",
    "        #Gram_inv = np.linalg.inv(self.Lambda0[self.At, :, :] + Gram)\n",
    "        #self.inv_Grams[self.At,:,:] = Gram_inv\n",
    "        self.Grams[self.At,:,:] = Gram\n",
    "        \n",
    "    for i in range(self.K):\n",
    "        # posterior sampling\n",
    "        Sigma_ti = np.linalg.inv(self.Lambda0[i, :, :] + self.Grams[i, :, :])\n",
    "        mu_ti = self.Lambda0[i, :, :].dot(self.Theta0[i, :]) + self.Grams[i, :, :].dot(self.irls_Theta[i,:])\n",
    "        mu_ti = Sigma_ti.dot(mu_ti)\n",
    "        theta_tilde = np.random.multivariate_normal(mu_ti, Sigma_ti)\n",
    "        self.mu[i] = self.env.X[i, :].dot(theta_tilde)\n",
    "    arm = np.argmax(self.mu)\n",
    "    self.At = arm\n",
    "    #print(self.irls_Theta[arm, :], arm)\n",
    "    return arm\n",
    "\n",
    "  @staticmethod\n",
    "  def print():\n",
    "    return \"GLM-TSL\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class meTS:\n",
    "  def __init__(self, env, n, params):\n",
    "    self.env = env  # bandit environment that the agent interacts with\n",
    "    self.K = self.env.K  # number of arms\n",
    "    self.d = self.env.d  # number of features\n",
    "    self.n = n  # horizon\n",
    "    self.A = self.env.A\n",
    "    self.L = self.A.shape[1]\n",
    "    self.mu_psi = np.copy(self.env.mu_psi)\n",
    "    self.Sigma_psi = np.copy(self.env.Sigma_psi)\n",
    "    self.Sigma0 = np.copy(self.env.Sigma0)\n",
    "    self.sigma = self.env.sigma  # reward noise\n",
    "    \n",
    "    self.irls_Theta = np.zeros((self.K, self.d))\n",
    "    self.irls_error = 1e-3\n",
    "    self.irls_num_iter = 1000\n",
    "    self.batch_size = 30 #self.n\n",
    "    \n",
    "    # override default values\n",
    "    for attr, val in params.items():\n",
    "      if isinstance(val, np.ndarray):\n",
    "        setattr(self, attr, np.copy(val))\n",
    "      else:\n",
    "        setattr(self, attr, val)\n",
    "\n",
    "    self.Lambda_psi = np.linalg.inv(self.Sigma_psi)\n",
    "    self.Lambda0 = np.zeros((self.K, self.d, self.d))\n",
    "    for i in range(self.K):\n",
    "      self.Lambda0[i, :, :] = np.linalg.inv(self.Sigma0[i, :, :])\n",
    "    \n",
    "    self.Theta0 = np.copy(self.env.mar_Theta0) #np.zeros((self.K, self.d))\n",
    "    \n",
    "    # sufficient statistics\n",
    "    self.G = np.zeros((self.K, self.d, self.d))\n",
    "    self.B = np.zeros((self.K, self.d))\n",
    "    \n",
    "    self.pulls = np.zeros(self.K, dtype=int) # number of observations for each arm    \n",
    "    self.context_ndx = [[] for i in range(self.K)]\n",
    "    self.r = [[] for i in range(self.K)]\n",
    "        \n",
    "  def sigmoid(self, x):\n",
    "    y = 1 / (1 + np.exp(- x))\n",
    "    return y\n",
    "\n",
    "  def solve(self, arm):\n",
    "    # iterative reweighted least squares for Bayesian logistic regression\n",
    "    # Sections 4.3.3 and 4.5.1 in Bishop (2006)\n",
    "    # Pattern Recognition and Machine Learning\n",
    "    small_eye = 1e-5 * np.eye(self.d)\n",
    "    theta = np.copy(self.irls_Theta[arm,:])\n",
    "    nbr_obs = self.pulls[arm]\n",
    "    t = self.r[arm]\n",
    "    context_ndx = self.context_ndx[arm]\n",
    "    num_iter = 0\n",
    "    \n",
    "    while num_iter < self.irls_num_iter:\n",
    "        theta_old = np.copy(theta)\n",
    "        Gram =  small_eye #self.Lambda0[arm, :, :]\n",
    "        Phiyt = np.zeros(self.d)\n",
    "\n",
    "        if nbr_obs <= self.batch_size:\n",
    "            batch = np.arange(nbr_obs)\n",
    "        else:\n",
    "            batch = np.random.choice(nbr_obs, size=self.batch_size)\n",
    "\n",
    "        for i in batch:\n",
    "            x = self.env.contexts[context_ndx[i],:]\n",
    "            y = self.sigmoid((x * theta).sum())\n",
    "            Gram += y * (1-y) * np.outer(x, x) \n",
    "            Phiyt += (y-t[i]) * x\n",
    "\n",
    "        PhiRz = Gram.dot(theta) - Phiyt\n",
    "        theta = np.linalg.solve(Gram, PhiRz)\n",
    "        \n",
    "        if np.linalg.norm(theta - theta_old) < self.irls_error:\n",
    "            break;\n",
    "        num_iter += 1\n",
    "    \n",
    "    if num_iter == self.irls_num_iter:\n",
    "        self.irls_Theta[arm,:] = self.Theta0[arm,:]\n",
    "    else:\n",
    "        self.irls_Theta[arm,:] = np.copy(theta)\n",
    "\n",
    "    return theta, Gram\n",
    "\n",
    "\n",
    "  def update(self, t, arm, r):    \n",
    "    self.r[arm].append(r)\n",
    "    self.pulls[arm] += 1\n",
    "    self.context_ndx[arm].append(self.env.ndx[arm])\n",
    "    \n",
    "    x = self.env.X[arm, :]\n",
    "    theta, self.G[arm, :, :] = self.solve(arm)\n",
    "    self.B[arm,:] = self.G[arm, :, :].dot(theta)\n",
    "\n",
    "  def get_arm(self, t):\n",
    "    small_eye = 1e-5 * np.eye(self.d)\n",
    "    \n",
    "    # effect parameter posterior\n",
    "    Lambda_t = np.copy(self.Lambda_psi)\n",
    "    mu_t = self.Lambda_psi.dot(self.mu_psi)\n",
    "    for i in range(self.K):\n",
    "      aiai = np.outer(self.A[i, :], self.A[i, :])\n",
    "      inv_Gi = np.linalg.inv(self.G[i, :, :] + small_eye)\n",
    "      prior_adjusted_Gi = np.linalg.inv(self.Sigma0[i, :, :] + inv_Gi)\n",
    "      Lambda_t += np.kron(aiai, prior_adjusted_Gi)\n",
    "      prior_adjusted_Bi = prior_adjusted_Gi.dot(inv_Gi.dot(self.B[i, :]))\n",
    "      mu_t += np.outer(self.A[i, :], prior_adjusted_Bi).flatten()\n",
    "    \n",
    "    # posterior sampling\n",
    "    Sigma_t = np.linalg.inv(Lambda_t)\n",
    "    mu_t = Sigma_t.dot(mu_t)\n",
    "    Psi_tilde = np.random.multivariate_normal(mu_t, Sigma_t)\n",
    "    matPsi_tilde = np.reshape(Psi_tilde, (self.L, self.d))  # matrix version\n",
    "    \n",
    "    self.mu = np.zeros(self.K)\n",
    "    for i in range(self.K):\n",
    "      # arm parameter posterior\n",
    "      Sigma_ti = np.linalg.inv(self.Lambda0[i, :, :] + self.G[i, :, :])\n",
    "      self.Theta0[i, :] = self.A[i, :].dot(matPsi_tilde)\n",
    "      mu_ti = self.Lambda0[i, :, :].dot(self.Theta0[i, :]) + self.B[i, :]\n",
    "      mu_ti = Sigma_ti.dot(mu_ti)\n",
    "      \n",
    "      # posterior sampling\n",
    "      theta_tilde = np.random.multivariate_normal(mu_ti, Sigma_ti)\n",
    "      self.mu[i] = self.env.X[i, :].dot(theta_tilde)\n",
    "    \n",
    "    arm = np.argmax(self.mu)\n",
    "    return arm\n",
    "\n",
    "  @staticmethod\n",
    "  def print():\n",
    "    return \"meTS-GLM\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FactoredmeTS:\n",
    "  def __init__(self, env, n, params):\n",
    "    self.env = env  # bandit environment that the agent interacts with\n",
    "    self.K = self.env.K  # number of arms\n",
    "    self.d = self.env.d  # number of features\n",
    "    self.n = n  # horizon\n",
    "    self.A = self.env.A\n",
    "    self.L = self.A.shape[1]\n",
    "    self.mu_psi = np.copy(self.env.mu_psi)\n",
    "    self.Sigma_psi = np.copy(self.env.Sigma_psi)\n",
    "    self.Sigma0 = np.copy(self.env.Sigma0)\n",
    "    self.sigma = self.env.sigma  # reward noise\n",
    "    \n",
    "    self.irls_Theta = np.zeros((self.K, self.d))\n",
    "    self.irls_error = 1e-3\n",
    "    self.irls_num_iter = 1000\n",
    "    self.batch_size = 30 #self.n\n",
    "    \n",
    "    # override default values\n",
    "    for attr, val in params.items():\n",
    "      if isinstance(val, np.ndarray):\n",
    "        setattr(self, attr, np.copy(val))\n",
    "      else:\n",
    "        setattr(self, attr, val)\n",
    "\n",
    "    self.Lambda_psi = np.linalg.inv(self.Sigma_psi)\n",
    "    self.Lambda0 = np.zeros((self.K, self.d, self.d))\n",
    "    for i in range(self.K):\n",
    "      self.Lambda0[i, :, :] = np.linalg.inv(self.Sigma0[i, :, :])\n",
    "    \n",
    "    self.Theta0 = np.copy(self.env.mar_Theta0) #np.zeros((self.K, self.d))\n",
    "    \n",
    "    # sufficient statistics\n",
    "    self.G = np.zeros((self.K, self.d, self.d))\n",
    "    self.B = np.zeros((self.K, self.d))\n",
    "    \n",
    "    self.pulls = np.zeros(self.K, dtype=int) # number of observations for each arm    \n",
    "    self.context_ndx = [[] for i in range(self.K)]\n",
    "    self.r = [[] for i in range(self.K)]\n",
    "        \n",
    "  def sigmoid(self, x):\n",
    "    y = 1 / (1 + np.exp(- x))\n",
    "    return y\n",
    "\n",
    "  def solve(self, arm):\n",
    "    # iterative reweighted least squares for Bayesian logistic regression\n",
    "    # Sections 4.3.3 and 4.5.1 in Bishop (2006)\n",
    "    # Pattern Recognition and Machine Learning\n",
    "    small_eye = 1e-5 * np.eye(self.d)\n",
    "    theta = np.copy(self.irls_Theta[arm,:])\n",
    "    nbr_obs = self.pulls[arm]\n",
    "    t = self.r[arm]\n",
    "    context_ndx = self.context_ndx[arm]\n",
    "    num_iter = 0\n",
    "    \n",
    "    while num_iter < self.irls_num_iter:\n",
    "        theta_old = np.copy(theta)\n",
    "        Gram =  small_eye #self.Lambda0[arm, :, :]\n",
    "        Phiyt = np.zeros(self.d)\n",
    "\n",
    "        if nbr_obs <= self.batch_size:\n",
    "            batch = np.arange(nbr_obs)\n",
    "        else:\n",
    "            batch = np.random.choice(nbr_obs, size=self.batch_size)\n",
    "\n",
    "        for i in batch:\n",
    "            x = self.env.contexts[context_ndx[i],:]\n",
    "            y = self.sigmoid((x * theta).sum())\n",
    "            Gram += y * (1-y) * np.outer(x, x) \n",
    "            Phiyt += (y-t[i]) * x\n",
    "\n",
    "        PhiRz = Gram.dot(theta) - Phiyt\n",
    "        theta = np.linalg.solve(Gram, PhiRz)\n",
    "        \n",
    "        if np.linalg.norm(theta - theta_old) < self.irls_error:\n",
    "            break;\n",
    "        num_iter += 1\n",
    "    \n",
    "    if num_iter == self.irls_num_iter:\n",
    "        self.irls_Theta[arm,:] = self.Theta0[arm,:]\n",
    "    else:\n",
    "        self.irls_Theta[arm,:] = np.copy(theta)\n",
    "\n",
    "    return theta, Gram\n",
    "\n",
    "\n",
    "  def update(self, t, arm, r):    \n",
    "    self.r[arm].append(r)\n",
    "    self.pulls[arm] += 1\n",
    "    self.context_ndx[arm].append(self.env.ndx[arm])\n",
    "    \n",
    "    x = self.env.X[arm, :]\n",
    "    theta, self.G[arm, :, :] = self.solve(arm)\n",
    "    self.B[arm,:] = self.G[arm, :, :].dot(theta)\n",
    "\n",
    "  def get_arm(self, t):\n",
    "    small_eye = 1e-5 * np.eye(self.d)\n",
    "    \n",
    "    # effect parameter posterior\n",
    "    Lambda_t = []\n",
    "    mu_t = []\n",
    "    for l in range(self.L):\n",
    "      Lambda_psi_l = self.Lambda_psi[l*self.d:(l+1)*self.d,l*self.d:(l+1)*self.d]\n",
    "      Lambda_t.append(np.copy(Lambda_psi_l))\n",
    "      mu_t.append(Lambda_psi_l.dot(self.mu_psi[l*self.d:(l+1)*self.d]))\n",
    "\n",
    "    for i in range(self.K):\n",
    "      inv_Gi = np.linalg.inv(self.G[i, :, :] + small_eye)\n",
    "      prior_adjusted_Gi = np.linalg.inv(self.Sigma0[i, :, :] + inv_Gi)\n",
    "      prior_adjusted_Bi = prior_adjusted_Gi.dot(inv_Gi.dot(self.B[i, :]))\n",
    "      for l in range(self.L):\n",
    "        Lambda_t[l] += (self.A[i, l]**2) * prior_adjusted_Gi\n",
    "        mu_t[l] += self.A[i, l] * prior_adjusted_Bi\n",
    "    \n",
    "    # posterior sampling\n",
    "    Sigma_t = []\n",
    "    for l in range(self.L):\n",
    "      Sigma_t.append(np.linalg.inv(Lambda_t[l]))\n",
    "      mu_t[l] = Sigma_t[l].dot(mu_t[l])\n",
    "\n",
    "    Sigma_t = block_diag(*Sigma_t)\n",
    "    mu_t = np.concatenate(mu_t)\n",
    "    \n",
    "    Psi_tilde = np.random.multivariate_normal(mu_t, Sigma_t)\n",
    "    matPsi_tilde = np.reshape(Psi_tilde, (self.L, self.d))  # matrix version\n",
    "    \n",
    "    self.mu = np.zeros(self.K)\n",
    "    for i in range(self.K):\n",
    "      # arm parameter posterior\n",
    "      Sigma_ti = np.linalg.inv(self.Lambda0[i, :, :] + self.G[i, :, :])\n",
    "      self.Theta0[i, :] = self.A[i, :].dot(matPsi_tilde)\n",
    "      mu_ti = self.Lambda0[i, :, :].dot(self.Theta0[i, :]) + self.B[i, :]\n",
    "      mu_ti = Sigma_ti.dot(mu_ti)\n",
    "      \n",
    "      # posterior sampling\n",
    "      theta_tilde = np.random.multivariate_normal(mu_ti, Sigma_ti)\n",
    "      self.mu[i] = self.env.X[i, :].dot(theta_tilde)\n",
    "    \n",
    "    arm = np.argmax(self.mu)\n",
    "    return arm\n",
    "\n",
    "  @staticmethod\n",
    "  def print():\n",
    "    return \"meTS-GLM-Fa\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinmeTS:\n",
    "  def __init__(self, env, n, params):\n",
    "    self.env = env  # bandit environment that the agent interacts with\n",
    "    self.K = self.env.K  # number of arms\n",
    "    self.d = self.env.d  # number of features\n",
    "    self.n = n  # horizon\n",
    "    self.A = self.env.A\n",
    "    self.L = self.A.shape[1]\n",
    "    self.mu_psi = np.copy(self.env.mu_psi)\n",
    "    self.Sigma_psi = np.copy(self.env.Sigma_psi)\n",
    "    self.Sigma0 = np.copy(self.env.Sigma0)\n",
    "    self.sigma = self.env.sigma  # reward noise\n",
    "\n",
    "    # override default values\n",
    "    for attr, val in params.items():\n",
    "      if isinstance(val, np.ndarray):\n",
    "        setattr(self, attr, np.copy(val))\n",
    "      else:\n",
    "        setattr(self, attr, val)\n",
    "\n",
    "    self.Lambda_psi = np.linalg.inv(self.Sigma_psi)\n",
    "    self.Lambda0 = np.zeros((self.K, self.d, self.d))\n",
    "    for i in range(self.K):\n",
    "      self.Lambda0[i, :, :] = np.linalg.inv(self.Sigma0[i, :, :])\n",
    "\n",
    "    # sufficient statistics\n",
    "    self.G = np.zeros((self.K, self.d, self.d))\n",
    "    self.B = np.zeros((self.K, self.d))\n",
    "\n",
    "  def update(self, t, arm, r):\n",
    "    # update sufficient statistics\n",
    "    x = self.env.X[arm, :]\n",
    "    self.G[arm, :, :] += np.outer(x, x) / np.square(self.sigma)\n",
    "    self.B[arm, :] += x * r / np.square(self.sigma)\n",
    "\n",
    "  def get_arm(self, t):\n",
    "    small_eye = 1e-3 * np.eye(self.d)\n",
    "    \n",
    "    # effect parameter posterior\n",
    "    Lambda_t = np.copy(self.Lambda_psi)\n",
    "    mu_t = self.Lambda_psi.dot(self.mu_psi)\n",
    "    for i in range(self.K):\n",
    "      aiai = np.outer(self.A[i, :], self.A[i, :])\n",
    "      inv_Gi = np.linalg.inv(self.G[i, :, :] + small_eye)\n",
    "      prior_adjusted_Gi = np.linalg.inv(self.Sigma0[i, :, :] + inv_Gi)\n",
    "      Lambda_t += np.kron(aiai, prior_adjusted_Gi)\n",
    "      prior_adjusted_Bi = prior_adjusted_Gi.dot(inv_Gi.dot(self.B[i, :]))\n",
    "      mu_t += np.outer(self.A[i, :], prior_adjusted_Bi).flatten()\n",
    "    \n",
    "    # posterior sampling\n",
    "    Sigma_t = np.linalg.inv(Lambda_t)\n",
    "    mu_t = Sigma_t.dot(mu_t)\n",
    "    Psi_tilde = np.random.multivariate_normal(mu_t, Sigma_t)\n",
    "    matPsi_tilde = np.reshape(Psi_tilde, (self.L, self.d))  # matrix version\n",
    "    \n",
    "    self.mu = np.zeros(self.K)\n",
    "    for i in range(self.K):\n",
    "      # arm parameter posterior\n",
    "      Sigma_ti = np.linalg.inv(self.Lambda0[i, :, :] + self.G[i, :, :])\n",
    "      mu_ti = self.Lambda0[i, :, :].dot(self.A[i, :].dot(matPsi_tilde)) + self.B[i, :]\n",
    "      mu_ti = Sigma_ti.dot(mu_ti)\n",
    "      \n",
    "      # posterior sampling\n",
    "      theta_tilde = np.random.multivariate_normal(mu_ti, Sigma_ti)\n",
    "      self.mu[i] = self.env.X[i, :].dot(theta_tilde)\n",
    "    \n",
    "    arm = np.argmax(self.mu)\n",
    "    return arm\n",
    "\n",
    "  @staticmethod\n",
    "  def print():\n",
    "    return \"meTS-Lin\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HierTS:\n",
    "  def __init__(self, env, n, params):\n",
    "    self.env = env  # bandit environment that the agent interacts with\n",
    "    self.K = self.env.K  # number of arms\n",
    "    self.d = self.env.d  # number of features\n",
    "    self.n = n  # horizon\n",
    "    self.A = self.env.A\n",
    "    self.L = self.A.shape[1]\n",
    "    self.mu_psi = np.mean(self.env.mu_psi.reshape(self.L, self.d), axis=0) # average of effect vectors as a single d-dimensional effect vector\n",
    "    self.Sigma_psi = (1/(self.L**2)) * np.sum([self.env.Sigma_psi[l*self.d:(l+1)*self.d,l*self.d:(l+1)*self.d] for l in range(self.L)], axis=0) # corresponding cov matrix\n",
    "    self.Sigma0 = np.copy(self.env.Sigma0)\n",
    "    self.sigma = self.env.sigma  # reward noise\n",
    "\n",
    "    # override default values\n",
    "    for attr, val in params.items():\n",
    "      if isinstance(val, np.ndarray):\n",
    "        setattr(self, attr, np.copy(val))\n",
    "      else:\n",
    "        setattr(self, attr, val)\n",
    "\n",
    "    self.Lambda_psi = np.linalg.inv(self.Sigma_psi)\n",
    "    self.Lambda0 = np.zeros((self.K, self.d, self.d))\n",
    "    for i in range(self.K):\n",
    "      self.Lambda0[i, :, :] = np.linalg.inv(self.Sigma0[i, :, :])\n",
    "\n",
    "    # sufficient statistics\n",
    "    self.G = np.zeros((self.K, self.d, self.d))\n",
    "    self.B = np.zeros((self.K, self.d))\n",
    "\n",
    "  def update(self, t, arm, r):\n",
    "    # update sufficient statistics\n",
    "    x = self.env.X[arm, :]\n",
    "    self.G[arm, :, :] += np.outer(x, x) / np.square(self.sigma)\n",
    "    self.B[arm, :] += x * r / np.square(self.sigma)\n",
    "\n",
    "  def get_arm(self, t):\n",
    "    small_eye = 1e-3 * np.eye(self.d)\n",
    "    \n",
    "    # effect parameter posterior\n",
    "    Lambda_t = np.copy(self.Lambda_psi)\n",
    "    mu_t = self.Lambda_psi.dot(self.mu_psi)\n",
    "    for i in range(self.K):\n",
    "      inv_Gi = np.linalg.inv(self.G[i, :, :] + small_eye)\n",
    "      prior_adjusted_Gi = np.linalg.inv(self.Sigma0[i, :, :] + inv_Gi)\n",
    "      Lambda_t += prior_adjusted_Gi\n",
    "      prior_adjusted_Bi = prior_adjusted_Gi.dot(inv_Gi.dot(self.B[i, :]))\n",
    "      mu_t += prior_adjusted_Bi\n",
    "    \n",
    "    # posterior sampling\n",
    "    Sigma_t = np.linalg.inv(Lambda_t)\n",
    "    mu_t = Sigma_t.dot(mu_t)\n",
    "    Psi_tilde = np.random.multivariate_normal(mu_t, Sigma_t)\n",
    "    \n",
    "    self.mu = np.zeros(self.K)\n",
    "    for i in range(self.K):\n",
    "      # arm parameter posterior\n",
    "      Sigma_ti = np.linalg.inv(self.Lambda0[i, :, :] + self.G[i, :, :])\n",
    "      mu_ti = self.Lambda0[i, :, :].dot(Psi_tilde) + self.B[i, :]\n",
    "      mu_ti = Sigma_ti.dot(mu_ti)\n",
    "      \n",
    "      # posterior sampling\n",
    "      theta_tilde = np.random.multivariate_normal(mu_ti, Sigma_ti)\n",
    "      self.mu[i] = self.env.X[i, :].dot(theta_tilde)\n",
    "    \n",
    "    arm = np.argmax(self.mu)\n",
    "    return arm\n",
    "\n",
    "  @staticmethod\n",
    "  def print():\n",
    "    return \"HierTS\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "O7WNIAqO-9FA",
    "outputId": "5d3114c6-ae59-4504-8b64-111712ff3f84",
    "tags": []
   },
   "outputs": [],
   "source": [
    "sigma = 1.0\n",
    "n = 5000\n",
    "num_runs = 50\n",
    "\n",
    "algs = [\n",
    "  (\"meTS\", {}, \"red\", \"-\", \"meTS-GLM\"),\n",
    "  (\"FactoredmeTS\", {}, \"orange\", \"-\", \"meTS-GLM-Fa\"),\n",
    "  (\"LinmeTS\", {}, \"purple\", \"-\", \"meTS-Lin\"),\n",
    " (\"LogTS\", {}, \"blue\", \"-\", \"GLM-TS\"),\n",
    "  (\"UCBLog\", {}, \"cyan\", \"-\", \"UCB-GLM\"),\n",
    "   (\"HierTS\", {}, \"gray\", \"-\", \"HierTS\"),\n",
    "]\n",
    "\n",
    "\n",
    "#exps = [\n",
    "#  {\"K\": 100, \"L\": 3, \"d\": 2},\n",
    "#  {\"K\": 100, \"L\": 3, \"d\": 5},\n",
    "#  {\"K\": 100, \"L\": 3, \"d\": 10},\n",
    "#  {\"K\": 50, \"L\": 3, \"d\": 2},\n",
    "#  {\"K\": 50, \"L\": 3, \"d\": 5},\n",
    "#  {\"K\": 50, \"L\": 3, \"d\": 10},\n",
    "#  {\"K\": 20, \"L\": 3, \"d\": 2},\n",
    "#  {\"K\": 20, \"L\": 3, \"d\": 5},\n",
    "#  {\"K\": 20, \"L\": 3, \"d\": 10}\n",
    "#]\n",
    "\n",
    "exps = [\n",
    "  {\"K\": 100, \"L\": 3, \"d\": 2}\n",
    "]\n",
    "\n",
    "\n",
    "for exp in exps:\n",
    "  # set parameters of the experiment\n",
    "  for attr, val in exp.items():\n",
    "    globals()[attr] = val\n",
    "\n",
    "  # bandit environments\n",
    "  envs = []\n",
    "  for run in range(num_runs):\n",
    "    # possible contexts\n",
    "    contexts = 2 * np.random.rand(100, d) - 1\n",
    "\n",
    "    # mixing coefficients\n",
    "    A = 3 * np.random.rand(K, L) - 1\n",
    "    \n",
    "    #matA: matrix formulation of the mixing weights for action parameters  \n",
    "    matA = np.zeros((K*d, L*d))\n",
    "    for i in range(K):\n",
    "        matA[i*d:(i+1)*d, :] = np.kron(A[i, :].T, np.eye(d))\n",
    "\n",
    "    # effect and arm priors\n",
    "    mu_psi = np.zeros(d * L)\n",
    "    mat_mu_Psi = np.reshape(mu_psi, (L, d))\n",
    "    Sigma_psi = 3 * np.eye(d * L)\n",
    "    Sigma0 = np.tile(np.eye(d), (K, 1, 1))\n",
    "    \n",
    "    # marginal uncertainty of arm parameters\n",
    "    mar_Theta0 = np.zeros((K, d))\n",
    "    mar_Sigma0 = np.copy(Sigma0)        \n",
    "    for i in range(K):\n",
    "        matAi = matA[i*d:(i+1)*d, :]\n",
    "        mar_Theta0[i, :] = matAi.dot(mu_psi)\n",
    "        mar_Sigma0[i, :, :] = Sigma0[i, :, :] + matAi.dot(Sigma_psi).dot(matAi.T)\n",
    "\n",
    "    # generate effect parameters\n",
    "    Psi = np.random.multivariate_normal(mu_psi, Sigma_psi)\n",
    "    matPsi = np.reshape(Psi, (L, d))  # matrix version\n",
    "\n",
    "    # generate arm parameters\n",
    "    Theta = np.random.randn(K, d)\n",
    "    for i in range(K):\n",
    "      Theta[i, :] = np.random.multivariate_normal(A[i, :].dot(matPsi), Sigma0[i, :, :])\n",
    "    # initialize bandit environment\n",
    "    env = LogBandit(K, contexts, Theta, sigma=sigma)\n",
    "\n",
    "    # pass parameters for algorithm initialization (not used in simulation)\n",
    "    env.A = A\n",
    "    env.mu_psi = mu_psi\n",
    "    env.Sigma_psi = Sigma_psi\n",
    "    env.Sigma0 = Sigma0\n",
    "    env.mar_Theta0 = mar_Theta0\n",
    "    env.mar_Sigma0 = mar_Sigma0\n",
    "\n",
    "    envs.append(env)\n",
    "    \n",
    "  #trained_algs = []\n",
    "  # simulation\n",
    "  for alg in algs:\n",
    "    # all runs for a single algorithm\n",
    "    alg_class = globals()[alg[0]]\n",
    "    regret, logs = evaluate(alg_class, alg[1], envs, n)\n",
    "    #regret, logs = evaluate_one(alg_class, alg[1], envs[0], n)\n",
    "    \n",
    "    #trained_algs.append(logs)\n",
    "    # # save results\n",
    "    #fname = \"Results/log_%s_K=%d_L=%d_d=%d\" % (alg[4], K, L, d)\n",
    "    #np.save(fname + \".npy\", regret)\n",
    "\n",
    "    # plot\n",
    "    cum_regret = regret.cumsum(axis=0)\n",
    "    step = np.arange(1, n + 1)\n",
    "    sube = (step.size // 10) * np.arange(1, 11) - 1\n",
    "    plt.plot(step, cum_regret.mean(axis=1),\n",
    "      alg[2], dashes=linestyle2dashes(alg[3]), label=alg[4])\n",
    "    plt.errorbar(step[sube], cum_regret[sube, :].mean(axis=1),\n",
    "      cum_regret[sube, :].std(axis=1) / np.sqrt(cum_regret.shape[1]),\n",
    "      fmt=\"none\", ecolor=alg[2])\n",
    "\n",
    "  plt.title(\"Log Bandit, K = %d, L = %d, d = %d\" % (K, L, d))\n",
    "  plt.xlabel(\"Round n\")\n",
    "  plt.ylabel(\"Regret\")\n",
    "  plt.ylim(bottom=0)\n",
    "  plt.legend(loc=\"upper left\", frameon=False)\n",
    "\n",
    "  plt.tight_layout()\n",
    "  plt.show()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "GLMBandit.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python Criteo (MOAB #49947)",
   "language": "python",
   "name": "python-kernel-49947"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
